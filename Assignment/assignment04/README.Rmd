---
title: "assignment04"
author: "sl"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# HPC

## Problem 1: Make sure your code is nice
Rewrite the following R functions to make them faster. It is OK (and recommended) to take a look at Stackoverflow and Google

```{r}
mat <- matrix(1:16, ncol = 4)
mat
```

```{r}
# Total row sums
fun1 <- function(mat) {
  n <- nrow(mat)
  ans <- double(n) 
  for (i in 1:n) {
    ans[i] <- sum(mat[i, ])
  }
  ans
}

fun1(mat)

fun1alt <- function(mat) {
  # YOUR CODE HERE
  n <- nrow(mat)
  ans <- double(n)
  ans <- rowSums(mat)
  
  return(ans)
}

fun1alt(mat)


# Cumulative sum by row
fun2 <- function(mat) {
  n <- nrow(mat)
  k <- ncol(mat)
  ans <- mat
  for (i in 1:n) {
    for (j in 2:k) {
      ans[i,j] <- mat[i, j] + ans[i, j - 1]
    }
  }
  ans
}

fun2(mat)

library(data.table)
fun2alt <- function(mat) {
  # YOUR CODE HERE
  ans <- t(apply(mat, 1, cumsum))
  
  return(ans)
}

fun2alt(mat)

# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)

# Test for the first
microbenchmark::microbenchmark(
  fun1(dat),
  fun1alt(dat), check = "equivalent"
)

# Test for the second
microbenchmark::microbenchmark(
  fun2(dat),
  fun2alt(dat), check = "equivalent"
)
```

I have to remove unit = "relative" to avoid an error.

## Problem 2: Make things run faster with parallel computing
The following function allows simulating PI

```{r}
sim_pi <- function(n = 1000, i = NULL) {
  p <- matrix(runif(n*2), ncol = 2)
  mean(rowSums(p^2) < 1) * 4
}

# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132
```

```{r}
# This runs the simulation a 4,000 times, each with 10,000 points
set.seed(1231)
system.time({
  ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
  print(mean(ans))
})
```

```{r}
# YOUR CODE HERE
library(parallel)

# Setup
cl <- makePSOCKcluster(4)  
clusterSetRNGStream(cl, 123)

# Number of simulations we want each time to run
nsim <- 1000

# We need to make -nsim- and sim_pi available to the
# cluster
clusterExport(cl, c("nsim", "sim_pi"))

system.time({
  # YOUR CODE HERE
  ans <- parLapply(cl, 1:4000, sim_pi(nsim) )
  print(mean(ans))
  # YOUR CODE HERE
})

```

```{r}
library(parallel)
my_boot <- function(dat, stat, R, ncpus = 1L) {
  
  # Getting the random indices
  n <- nrow(dat)
  idx <- matrix(sample.int(n, n*R, TRUE), nrow=n, ncol=R)
 
  # Making the cluster using `ncpus`
  # STEP 1: GOES HERE
  cl <- makePSOCKcluster(4)  
  clusterSetRNGStream(cl, 123) # Equivalent to `set.seed(123)`
  
  # STEP 2: GOES HERE
  
  clusterExport(cl, c("stat", "dat", "idx"), envir = environment())
  
    # STEP 3: THIS FUNCTION NEEDS TO BE REPLACES WITH parLapply
  ans <- parLapply(cl, seq_len(R), function(i) {
    stat(dat[idx[,i], , drop=FALSE])
  })
  
  # Coercing the list into a matrix
  ans <- do.call(rbind, ans)
  
  # STEP 4: GOES HERE
  
  ans
  
}
```

# SQL
Setup a temporary database by running the following chunk

```{r}
if (!require(RSQLite)) install.packages(c("RSQLite"))
if (!require(DBI)) install.packages(c("DBI"))


library(RSQLite)
library(DBI)

# Initialize a temporary in memory database
con <- dbConnect(SQLite(), ":memory:")

# Download tables
film <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film.csv")
film_category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film_category.csv")
category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/category.csv")

# Copy data.frames to database
dbWriteTable(con, "film", film)
dbWriteTable(con, "film_category", film_category)
dbWriteTable(con, "category", category)

```

## Question 1
How many movies is there available in each rating category.

```{sql, connection = con}
#PRAGMA table_info(film)
#PRAGMA table_info(film_category)
#PRAGMA table_info(category)
```

```{sql, connection = con}
SELECT rating, COUNT(*) AS N
FROM film
GROUP BY rating
ORDER BY N DESC
```

## Question 2
What is the average replacement cost and rental rate for each rating category.

```{sql, connection = con}
SELECT rating, 
        AVG(replacement_cost) AS avg_replacement_cost,
        AVG(rental_rate) AS avg_rental_rate
FROM film
GROUP BY rating
ORDER BY avg_replacement_cost DESC
```

## Question 3
Use table film_category together with film to find the how many films there are within each category ID

```{sql, connection = con}
SELECT category_id, COUNT(*) AS N
FROM film_category AS fc INNER JOIN film AS f
ON fc.film_id = f.film_id
GROUP BY category_id
ORDER BY category_id ASC
```

## Question 4
Incorporate table category into the answer to the previous question to find the name of the most popular category.

```{sql, connection = con}
SELECT c.name, COUNT(*) AS N
FROM ((film_category AS fc
INNER JOIN film AS f ON fc.film_id = f.film_id)
INNER JOIN category AS c ON fc.category_id = c.category_id)
GROUP BY c.name
ORDER BY N DESC
```

## Cleanup
Run the following chunk to disconnect from the connection.
```{r}
# clean up
dbDisconnect(con)
```


